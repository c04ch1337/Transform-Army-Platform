{
  "agent_id": "qa-auditor",
  "name": "QA Auditor",
  "version": "1.0.0",
  "description": "Quality assurance and validation specialist. Scores agent outputs against rubrics, detects drift, identifies edge cases, and ensures consistent quality across operations.",
  "status": "active",
  "configuration": {
    "model": {
      "provider": "openai",
      "model_name": "gpt-4",
      "temperature": 0.1,
      "max_tokens": 1000,
      "fallback_model": "gpt-3.5-turbo"
    },
    "system_prompt": "You are the QA Auditor, the quality assurance specialist responsible for validating agent outputs, scoring performance against rubrics, identifying drift and edge cases, and ensuring consistent quality across all agent operations.\n\n**Your Mission:** Serve as the final checkpoint ensuring outputs meet quality standards before reaching customers or being committed to systems.\n\n**Core Responsibilities:**\n- Score agent outputs against predefined rubrics (0-10 scale)\n- Check compliance with business rules and policies\n- Verify data accuracy and completeness\n- Monitor performance trends and detect anomalies\n- Generate test cases from real interactions\n- Provide feedback for continuous improvement\n\n**General Quality Rubric (50 points total):**\n1. **Accuracy (10 points):** All facts correct, properly verified\n2. **Completeness (10 points):** All required elements present\n3. **Format & Structure (10 points):** Proper formatting, clear organization\n4. **Tone & Style (10 points):** Brand voice, appropriate tone\n5. **Compliance (10 points):** All policies followed, no violations\n\n**Quality Bands:**\n- 9.0-10.0: Excellent (no action needed)\n- 8.0-8.9: Good (minor improvements possible)\n- 7.0-7.9: Acceptable (meets minimum standards)\n- 6.0-6.9: Needs Improvement (flag for review)\n- Below 6.0: Unacceptable (block or escalate)\n\n**Quality Gates:**\n- **Block Output:** Score <6.0, compliance violations, PII leakage, security concerns\n- **Flag for Review:** Score 6.0-6.9, low confidence, edge case, multiple retries\n- **Monitor:** Score 7.0-7.9, minor issues, cost above average\n- **Approve:** Score ≥8.0\n\n**Drift Detection:**\nAlert when:\n- Mean quality score drops >0.5 points\n- Standard deviation increases >20%\n- New error types appear frequently\n- Success rate declining\n- Response time or cost increasing\n\n**Sampling Strategy:**\n- High-risk agents: 100% sampling\n- Medium-risk: 20% sampling\n- Low-risk: 5% sampling\n- P1 issues: Always 100%\n- Random sampling for baseline\n\n**Always:**\n- Use rubrics consistently\n- Provide specific feedback\n- Track trends over time\n- Minimize false positives\n- Document edge cases\n- Generate actionable insights",
    "role_instructions": "**Real-Time Output Validation:**\n1. Receive agent output for validation\n2. Identify agent type and applicable rubric\n3. Extract components to evaluate\n4. Score each rubric dimension (0-10):\n   - Accuracy: Facts correct?\n   - Completeness: All elements present?\n   - Format: Proper structure?\n   - Tone: Appropriate style?\n   - Compliance: Policies followed?\n5. Calculate total score (average of dimensions)\n6. Check quality gates:\n   - <6.0 → Block and escalate\n   - 6.0-6.9 → Allow with warning\n   - 7.0+ → Approve\n7. If blocked:\n   - Prevent output from customer\n   - Alert agent owner\n   - Log incident with details\n   - Request human review\n8. If approved:\n   - Log evaluation score\n   - Track metrics\n   - Include in reports\n9. Return validation result\n\n**Batch Quality Audit (Daily):**\n1. Select sample of outputs (past 24 hours)\n2. Apply sampling strategy\n3. For each output:\n   - Retrieve full context\n   - Apply relevant rubric\n   - Score all dimensions\n   - Flag anomalies\n4. Aggregate results:\n   - Mean score by agent\n   - Score distribution\n   - Common failures\n   - Drift indicators\n5. Compare to baseline\n6. Generate daily report\n7. Alert if thresholds breached\n\n**Drift Detection (Weekly):**\n1. Collect quality metrics (rolling 7-day window)\n2. Calculate baselines:\n   - Mean score\n   - Standard deviation\n   - P95 and P99\n3. Compare current to baseline\n4. Check drift thresholds\n5. If drift detected:\n   - Analyze recent outputs\n   - Identify contributing factors\n   - Categorize severity\n   - Generate drift report\n6. Alert engineering team\n7. Track remediation\n8. Verify correction\n\n**Test Case Generation:**\n1. Analyze recent interactions\n2. Identify:\n   - Edge cases\n   - Fixed bugs\n   - High-quality examples\n   - Novel patterns\n3. For each scenario:\n   - Extract input parameters\n   - Document expected output\n   - Define acceptance criteria\n   - Specify rubric thresholds\n4. Convert to test format\n5. Add to test suite\n6. Validate tests\n7. Add to regression suite",
    "tools": [
      {
        "tool_id": "eval_rubric_score",
        "enabled": true,
        "required": true
      },
      {
        "tool_id": "analytics_agent_performance",
        "enabled": true,
        "required": true
      },
      {
        "tool_id": "analytics_quality_trends",
        "enabled": true,
        "required": true
      },
      {
        "tool_id": "test_case_generate",
        "enabled": true,
        "required": false
      },
      {
        "tool_id": "slack_notify",
        "enabled": true,
        "required": true
      }
    ],
    "knowledge_bases": [
      {
        "kb_id": "qa_rubrics",
        "description": "Evaluation rubrics and standards",
        "enabled": true
      },
      {
        "kb_id": "test_cases",
        "description": "Test case library",
        "enabled": true
      }
    ],
    "input_schema": {
      "type": "object",
      "properties": {
        "operation": {
          "type": "string",
          "enum": ["validate_output", "batch_audit", "drift_detection", "generate_tests"],
          "description": "QA operation to perform"
        },
        "agent_id": {
          "type": "string",
          "description": "Agent whose output to evaluate"
        },
        "output_data": {
          "type": "object",
          "description": "Agent output to evaluate"
        },
        "context": {
          "type": "object",
          "description": "Additional context for evaluation"
        },
        "time_range": {
          "type": "string",
          "description": "Time range for batch operations"
        }
      },
      "required": ["operation"]
    },
    "output_schema": {
      "type": "object",
      "properties": {
        "operation": {
          "type": "string"
        },
        "validation_result": {
          "type": "string",
          "enum": ["approved", "flagged", "blocked", "error"]
        },
        "quality_score": {
          "type": "number",
          "minimum": 0,
          "maximum": 10
        },
        "rubric_scores": {
          "type": "object",
          "properties": {
            "accuracy": {"type": "number"},
            "completeness": {"type": "number"},
            "format": {"type": "number"},
            "tone": {"type": "number"},
            "compliance": {"type": "number"}
          }
        },
        "issues_found": {
          "type": "array",
          "items": {
            "type": "object",
            "properties": {
              "category": {"type": "string"},
              "severity": {"type": "string"},
              "description": {"type": "string"},
              "recommendation": {"type": "string"}
            }
          }
        },
        "drift_detected": {
          "type": "boolean"
        },
        "drift_severity": {
          "type": "string",
          "enum": ["none", "low", "medium", "high", "critical"]
        },
        "tests_generated": {
          "type": "integer"
        },
        "feedback": {
          "type": "string",
          "description": "Actionable feedback for improvement"
        }
      },
      "required": ["operation", "validation_result"]
    }
  },
  "performance": {
    "sla": {
      "validation_time_seconds": 15,
      "batch_audit_hours": 24,
      "report_generation_minutes": 30
    },
    "thresholds": {
      "detection_accuracy": 0.95,
      "false_positive_rate_max": 0.05,
      "false_negative_rate_max": 0.03
    },
    "cost_budget": {
      "per_evaluation": 0.05,
      "daily_max": 15.00
    }
  },
  "monitoring": {
    "metrics": [
      "detection_accuracy",
      "false_positive_rate",
      "false_negative_rate",
      "review_throughput",
      "feedback_impact",
      "quality_improvement"
    ],
    "alerts": [
      {
        "type": "quality_collapse",
        "condition": "multiple_agents_score < 7.0",
        "channel": "slack",
        "priority": "critical"
      },
      {
        "type": "drift_detected",
        "condition": "drift_severity >= high",
        "channel": "email"
      }
    ]
  },
  "rubrics": {
    "bdr_concierge": {
      "qualification_accuracy": "BANT criteria applied correctly",
      "data_completeness": "CRM fields populated properly",
      "email_tone": "Professional and personalized",
      "booking_accuracy": "Meeting details complete and correct"
    },
    "support_concierge": {
      "priority_accuracy": "Ticket priority assigned correctly",
      "kb_search_quality": "Search performed thoroughly",
      "solution_accuracy": "Solution verified and correct",
      "escalation_quality": "Context comprehensive if escalated"
    },
    "research_recon": {
      "source_quality": "Sources credible and recent",
      "citation_completeness": "All claims properly cited",
      "analysis_depth": "Insights valuable and actionable",
      "report_format": "Professional and well-structured"
    },
    "ops_sapper": {
      "alert_accuracy": "No false positives",
      "monitoring_coverage": "All metrics checked",
      "report_timeliness": "Delivered on schedule",
      "data_accuracy": "Calculations correct"
    },
    "knowledge_librarian": {
      "article_accuracy": "Information correct and verified",
      "metadata_completeness": "All fields populated",
      "categorization": "Appropriate category assigned",
      "gap_analysis": "Gaps identified accurately"
    }
  },
  "sampling_rates": {
    "high_risk": {
      "agents": ["bdr-concierge", "support-concierge"],
      "rate": 1.0,
      "reason": "Customer-facing, high impact"
    },
    "medium_risk": {
      "agents": ["research-recon", "knowledge-librarian"],
      "rate": 0.2,
      "reason": "Internal use, moderate impact"
    },
    "low_risk": {
      "agents": ["ops-sapper"],
      "rate": 0.05,
      "reason": "Monitoring only, low customer impact"
    }
  },
  "escalation_criteria": {
    "immediate": [
      "Compliance score < 6.0 (policy violation)",
      "Security concern flagged",
      "PII leakage detected",
      "Offensive content",
      "Multiple agents failing simultaneously"
    ],
    "business_hours": [
      "Quality trending down 3+ days",
      "Drift detected (high severity)",
      "Test failures in regression suite",
      "Cost anomaly (quality vs cost ratio)"
    ],
    "weekly_report": [
      "Quality trends and comparisons",
      "Agent performance scorecards",
      "Improvement recommendations",
      "Test coverage gaps"
    ]
  },
  "metadata": {
    "created_at": "2025-10-31T00:00:00Z",
    "updated_at": "2025-10-31T00:00:00Z",
    "created_by": "system",
    "tags": ["quality", "qa", "validation", "testing", "ground-forces"],
    "squad": "all-squads",
    "phase": "phase-1"
  }
}